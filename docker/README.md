[Back](../README.md)

# Docker

![architecture](https://wiki.aquasec.com/download/attachments/2854889/Docker_Architecture.png?version=1&modificationDate=1547002099000&api=v2)

## Containers

A container is a standard unit of software that packages up code and all its dependencies.

Docker uses namespaces (feature in the Linux Kernel) to provide the isolation that containers need.
So, a container is a main process that runs in a namespace, and all the sub-processes the container runs are children of that main process, under the same namespace.
If the process that runs the container is killed, the container is killed too.

The main difference between a container and a virtual machine is that a container doest not need to contain a complete operating system. It can reuse the same operating system that is running on the host.

### Cgroups

Cgroups allow us to control the resources that a container uses, such as memory, CPU, disk, network, etc.
They allow us to control over what host resources are allocated to the container, and when they are allocated.

### File Systems

OFS (Overlay File System) is a file system that allows us to share files between containers.

## Docker host

Docker host is the machine that runs Docker.

## Docker daemon

Docker daemon is the component on the Docker host that does the work of building and running containers.
The Docker daemon listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes.

## Images

A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.

Images in docker container are immutable, we can write and modify something inside the container (not in the image), but when we stop the container, we will lose everything.
However, to avoid losing data, Docker provides volumes and bind mounts, two mechanisms for persisting data in containers.
Using this technique we mount a folder (or a volume) that it is inside our computer to the container, so if the container terminate, these files are inside our computer, and we don't lose it.

### Volumes

Volumes are the preferred mechanism for persisting data generated by and used by Docker containers.
- Have much higher performance than bind mounts from Mac and Windows hosts
- Can be shared among multiple containers
- Easier to back up or migrate than bind mounts
- You can manage volumes using Docker CLI commands

## Dockerfile

Docker can build images automatically by reading the instructions from a Dockerfile.
A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image.

A Dockerfile is used to build an image from a base image. If we do not need to change anything in an image, we do not need to write a Dockerfile.

```Dockerfile
  FROM ubuntu:latest
  RUN apt-get update && apt-get install -y curl
  EXPOSE 8080
```

## Image registries

Docker Hub is the main registry for Docker images. It allows anyone to upload and download images.
There are many other registries, such as Docker.io, Quay.io, Amazon ECR, and others.

## Docker Compose

Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration.

Using Compose is basically a three-step process:
- Define your app’s environment with a Dockerfile, so it can be reproduced anywhere.
- Define the services that make up your app in docker-compose.yml, so they can be run together in an isolated environment.
- Run docker-compose up and Compose starts and runs your entire app.

## Commands

### Containers

```shell
docker ps
# list active (running) containers
```

```shell
docker run hello-word
# hello-word = image
# it uses image(hello-word):latest by default
# first it will download the image (pull) if it can't find it locally
# then it will run the entrypoint / command of the image, which will invoke an executable (shell script, binary, etc.)
# If we didn't inform a name, docker will generate a random weird name for the container
```

```shell
docker ps -a
# list all container even the inactive (stopped) ones
```

```shell
docker run -it ubuntu:latest bash
# :latest is redundant
# -it = -i -t
# -i = interactive mode, it will attach the terminal to the docker command we are executing (bash in this case)
# -t = tty = allow us to type something in the terminal attached with the -i option
# bash = command to run in the image
```

```shell
docker start <container_id> or <container_name>
# start again a stopped container
```

```shell
docker run -it --rm ubuntu:latest bash
# --rm will remove the container once it has stopped running
```

```shell
docker run nginx
# nginx = web server
# exposes :80 port OF THE CONTAINER!
# docker host = computer that executes the docker precesses
# container = simulates a different OS, with its own kernel and etc
# WHEN THE CONTAINER EXPOSES A PORT (:80 FOR EXAMPLE), IT DOEST NO MEAN THAT WE CAN ACCESS THAT ON THE DOCKER HOST, OR WHENEVER COMPUTER THAT IT IS EXECUTING THE DOCKER (CLI)
# --name option can be used to define a name
```

```shell
docker run -p 8080:80 nginx
# -p 8080:80 = now when I access the :8080 port on the computer I am executing this docker command (cli), I'll be redirected to the :80 port of the container
# it publishes the :80 port of the container on the :8080 port on my computer
```

```shell
docker run -d -p 8080:80 nginx
# -d = detached = it will detach the terminal with the docker container process
# run the docker container in the background
```

```shell
docker stop <container_id> or <container_name>
# stop a container
# useful when running a container in the background
```

```shell
docker rm <container_id> or <container_name>
# remove a container
# -f option can be user to force removing a container that is running
```

```shell
docker run --name nginx -d -p 8080:80 nginx
# full command with all the options we have seen before
```

```shell
docker exec nginx ls
# exec = execute = run a command in a container that is already running
# executes the ls command in the container with the name nginx
```

```shell
docker exec -it nginx bash
# executes the bash and opens the bash for typing commands
# remember to always use -it with the bash command, otherwise the bash command will execute and terminate in the sequence
```

```shell
docker rm $(docker ps -a -q) -f
# command to remove ALL containers
```

```shell
docker logs <container_id> or <container_name>
# show the logs of a container
```

### Bind Mounts and Volumes

```shell
docker run --name nginx -d -p 8080:80 -v ~/workspace/docker/html:/usr/share/nginx/html nginx
# -v option create the bind mount
# mount the folder inside my computer (~/workspace/docker/html) in the directory inside the container (/usr/share/nginx/html)
# we could also use "$(pwd)" to define the directory in our computer
# -v is an old option, and should be replaced by --mount
```

```shell
docker run --name nginx -d -p 8080:80 --mount type=bind,source="$(pwd)"/html,target=/usr/share/nginx/html nginx
# do the same that -v does, but with this new command --mount
# the main difference is that -v will create the directory in our machine case it doesn't exist, --mount will throw an error if the folder doesn't exist
```

```shell
docker volume ls
# list volumes
```

```shell
docker volume create myvolume
# creates a new volume
```

```shell
docker volume inspect myvolume
# show a volume in more details
# "Mountpoint" = path in your computer that the volume is saved
```

```shell
docker run --name nginx -d -p 8080:80 --mount type=volume,source=myvolume,target=/app nginx
# same command used before using volumes
```

```shell
docker run --name nginx -d -p 8080:80 -v myvolume:/app nginx
# same command used before using volumes
```

```shell
docker volume prune
# remove unused volumes
```

### Images

```shell
docker pull ubuntu
# just download the image, but don't start any container
```

```shell
docker images
# list all images in your computer
```

```shell
docker rmi ubuntu:latest
# remove a image
```

To create a new image, we need create a Dockerfile (Dockerfile is the "recipe" to create a new image).
We can create a new image based on an existing one, for example, to create a new nginx image based on a pre-existing nginx image, and include some new packages, like vim, we can use the following Dockerfile:

```Dockerfile
FROM nginx:latest

RUN apt-get update
RUN apt-get install vim -y
```

Then:

```shell
docker build -t dyarleniber/nginx-with-vim:latest .
# generates the image docker
# -t = tag/name
# dyarleniber = user on docker hub
# . = path to the dockerfile, in this case, the current directory
```

> If we change the Dockerfile name, we need to specify the name of the Dockerfile when building it, using the -f option:

```shell
docker build -t dyarleniber/laravel:prod laravel -f laravel/Dockerfile.prod
# dyarleniber/laravel:prod = image name
# laravel = path to the dockerfile
# laravel/Dockerfile.prod = name of the dockerfile
```

More commands of Dockerfile:

```Dockerfile
FROM nginx:latest

# creates this directory (if it doesn't exist) and use this directory as an entry point when I acess the container
WORKDIR /app

RUN apt-get update && \
	apt-get install vim -y

# copies files from a local source location to a destination in the Docker container
COPY html/ /usr/share/nginx/html
```

```Dockerfile
FROM ubuntu:latest

# CMD = command to execute when the container is started, it can be easily overwritten by the params when we run it
# Example: docker run --rm <image_name> echo "hi"
# in the above example, the echo "hi" will replace the CMD command below
CMD ["echo", "Hello World"]
```

```Dockerfile
FROM ubuntu:latest

# ENTRYPOINT is a fixed command that will be executed when the container is started, but it can`t be overwritten by the params when we run it
ENTRYPOINT ["echo", "Hello "]

# in this case, the CMD will be a variable command, that will be used as a parameter for the ENTRYPOINT
CMD ["World"]

# Running: "docker run --rm <image_name>" will print "Hello World"
# Running: "docker run --rm <image_name> X" will print "Hello X"
```

> A common technique is to define a shell script file (.sh) and use it as the ENTRYPOINT, like the example below:

```Dockerfile
FROM ubuntu:latest

ENTRYPOINT ["./script.sh"]

CMD ["echo", "Hi"]

# in order to use the CMD command with the ENTRYPOINT, we need to create a shell script file like the example below
```

```shell
#!/bin/sh

# script content

# the following command will execute all the parameters that we pass to the script when we run it
# Example: ./script.sh echo "hi"
# in the above example, the echo "hi" will be executed at the end of the script
# this way, we can use this script as the ENTRYPOINT of the container in the Dockerfile, and any possible command using the CMD command, or via parameters when we run the container, will be executed
exec "$@"
```

> To publish an image to Docker Hub, we need to log in to Docker Hub, build the image and publish it.

```shell
docker build -t dyarleniber/nginx-with-vim .
# dyarleniber is the user on docker hub
# the :latest tag is used by default to publish the image to the latest version

docker login
# log in to docker hub using the username and password

docker push dyarleniber/nginx-with-vim
# upload/publish the image to docker hub
```

> Each line (layer) of the Dockerfile will be cached, so if we run the Dockerfile again, without any changes, the cached layer will be used instead of creating a new one.

### Networking

> Networking is the process of connecting containers to each other.
> Docker uses the bridge network by default, but we can use other networks like the host network, or the overlay network.

> The bridge network (default) is a virtual network that connects all containers together.
> The host network is a virtual network that connects all containers to the host computer. All containers can access any port on the host computer, and the host computer can access the containers.
> The other ones are not so common, the bridge network is the most common one.

> The host network will not work in a macOS environment, because Docker on macOS creates a virtual machine with Linux, so the host machine will be the Linux virtual machine, and not the macOS one.
> On a Windows environment, it should work using WSL.
> Docker was designed to run on Linux!

```shell
docker network ls
# list all networks
```

```shell
docker network prune
# remove all networks that are not being used
```

```shell
docker network create --driver bridge mynetwork
# create a new network
# the driver is the type of network, in this case, it is redundant, because the default is bridge
```

```shell
docker network inspect mynetwork
# inspect a network
# under "containers" key, we can see the containers that are connected to the network
```

```shell
docker network inspect bridge
# inspect the bridge network
# under "containers" key, we can see the containers that are connected to the network
```

```shell
docker run -dit --name ubuntu1 --network mynetwork bash
docker run -dit --name ubuntu2 --network mynetwork bash

# now I can access the ubuntu2 container from the ubuntu1 container (and vice versa)
# for example, if I run "docker exec -it ubuntu1 bash" and inside the ubuntu1 run "ping ubuntu2", it will work
```

```shell
docker network connect mynetwork ubuntu3
# connect a pre-existing container to a network
```

> To access the host computer from a container (without using a network), we can access host.docker.internal instead of the host IP address.
> For example: "curl http://host.docker.internal:8080"

### docker-compose

```shell
docker-compose up
# start all containers
```

```shell
docker-compose down
# stop all containers
```

```shell
docker-compose build
# build all containers
```

```shell
docker-compose up -d
# start all containers in background
```

```shell
docker-compose ps
# list all containers of the docker-compose file
```

```shell
docker-compose up -d --build
# start all containers in background and build or re-build them
```
